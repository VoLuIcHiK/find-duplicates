{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoTokenizer, TimesformerModel\n",
    "from optimum.exporters.onnx import TextEncoderOnnxConfig #VisionOnnxConfig # Нужно добавить VisionOnnxConfig в импорт пакета\n",
    "from optimum.exporters.onnx.config import VisionOnnxConfig\n",
    "from optimum.utils.input_generators import DummyVisionInputGenerator\n",
    "from optimum.utils import NormalizedConfig\n",
    "from optimum.exporters.onnx import export\n",
    "from transformers import PretrainedConfig\n",
    "from typing import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = '../weights/csl_transformers_base'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генератор входов для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoInputGenerator(DummyVisionInputGenerator):\n",
    "    def generate(self, input_name: str, int_dtype, float_dtype, framework: str = \"pt\"):\n",
    "        return super().random_float_tensor(shape=[2, 8, 3, 224, 224], framework=framework)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конфиг для конвертации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTimesformerOnnxConfig(VisionOnnxConfig):\n",
    "\n",
    "    NORMALIZED_CONFIG_CLASS = NormalizedConfig\n",
    "    DUMMY_INPUT_GENERATOR_CLASSES = (VideoInputGenerator,)\n",
    "\n",
    "    @property\n",
    "    def inputs(self) -> Dict[str, Dict[int, str]]:\n",
    "        return {\n",
    "            \"pixel_values\": {0: \"batch_size\", 1: \"num_frames\", 2: \"num_channels\", 3: \"height\", 4: \"width\"},\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def outputs(self) -> Dict[str, Dict[int, str]]:\n",
    "        return {\n",
    "            \"last_hidden_state\": {0: \"batch_size\"},\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Конвертация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type timesformer to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "model = TimesformerModel.from_pretrained(WEIGHTS)\n",
    "config = PretrainedConfig.from_pretrained(WEIGHTS)\n",
    "\n",
    "onnx_path = Path(\"model.onnx\")\n",
    "onnx_config = MyTimesformerOnnxConfig(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using framework PyTorch: 2.4.1+cu121\n",
      "/home/borntowarn/projects/borntowarn/piracy_detection/venv/lib/python3.11/site-packages/transformers/models/timesformer/modeling_timesformer.py:110: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if embeddings.size(1) != self.position_embeddings.size(1):\n",
      "/home/borntowarn/projects/borntowarn/piracy_detection/venv/lib/python3.11/site-packages/transformers/models/timesformer/modeling_timesformer.py:139: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_frames != self.time_embeddings.size(1):\n"
     ]
    }
   ],
   "source": [
    "onnx_inputs, onnx_outputs = export(model, onnx_config, onnx_path, onnx_config.DEFAULT_ONNX_OPSET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запуск сессии ORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort.get_available_providers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2024-09-27 21:44:00.223146496 [W:onnxruntime:, session_state.cc:1166 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\u001b[m\n",
      "\u001b[0;93m2024-09-27 21:44:00.223187615 [W:onnxruntime:, session_state.cc:1168 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\u001b[m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimesformerModel(\n",
       "  (embeddings): TimesformerEmbeddings(\n",
       "    (patch_embeddings): TimesformerPatchEmbeddings(\n",
       "      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (time_drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): TimesformerEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): TimesformerLayer(\n",
       "        (drop_path): Identity()\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (1): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.00909090880304575)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (2): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.0181818176060915)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (3): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.027272727340459824)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (4): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.036363635212183)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (5): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.045454543083906174)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (6): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.054545458406209946)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (7): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.06363636255264282)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (8): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.0727272778749466)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (9): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.08181818574666977)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (10): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.09090909361839294)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (11): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.10000000149011612)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../weights/csl_transformers_base/model.onnx'\n",
    "options = ort.SessionOptions()\n",
    "options.graph_optimization_level = \\\n",
    "    ort.GraphOptimizationLevel.ORT_ENABLE_ALL \n",
    "sess = ort.InferenceSession(path, providers=['CUDAExecutionProvider'], sess_options=options)\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сранение скоростей работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "onnx_time = []\n",
    "torch_time = []\n",
    "total = 32\n",
    "batch = 16\n",
    "\n",
    "for i in range(total):\n",
    "    data = torch.rand([batch, 8, 3, 224, 224])\n",
    "    \n",
    "    t1 = time.time()\n",
    "    data = data.cuda()\n",
    "    with torch.no_grad():\n",
    "        orig = model(data)\n",
    "        orig.last_hidden_state.cpu()\n",
    "        torch_time.append(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(total):\n",
    "    inputs = {\n",
    "        \"pixel_values\": torch.rand([batch, 8, 3, 224, 224]).numpy().astype(np.float32),\n",
    "    }\n",
    "    \n",
    "    t1 = time.time()\n",
    "    outputs = sess.run(None, inputs)\n",
    "    onnx_time.append(time.time() - t1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33456847816705704\n",
      "0.40667273104190826\n"
     ]
    }
   ],
   "source": [
    "print(np.array(onnx_time).mean())\n",
    "print(np.array(torch_time).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение точности конвертации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand([batch, 8, 3, 224, 224])\n",
    "inputs = {\n",
    "    \"pixel_values\": data.numpy().astype(np.float32),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = sess.run(None, inputs)\n",
    "with torch.no_grad():\n",
    "    orig = model(data.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig.last_hidden_state[:, 0].cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002488792\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.abs(orig.last_hidden_state[:, 0].cpu().numpy() - outputs[0][:, 0]).max())\n",
    "print(np.abs(orig.last_hidden_state[:, 0].cpu().numpy() - outputs[0][:, 0]).min())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
