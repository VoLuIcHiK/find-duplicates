{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подгружаем оригинальную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from transformers import TimesformerModel, TimesformerConfig\n",
    "import torch\n",
    "from src.csl.models.model import SimilarityRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borntowarn/projects/borntowarn/piracy_detection/notebooks/../src/csl/models/model.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimilarityRecognizer(\n",
       "  (feature_extractor): Timesformer(\n",
       "    (model): VisionTransformer(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (time_drop): Dropout(p=0.0, inplace=False)\n",
       "      (blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (temporal_attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1-11): 11 x Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (temporal_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (temporal_attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (temporal_fc): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model = SimilarityRecognizer('base', 16)\n",
    "orig_model.load_pretrained_weights('../weights/base.pth')\n",
    "orig_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции для сопоставления словаря весов к transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert TimeSformer checkpoints from the original repository: https://github.com/MCG-NJU/TimeSformer\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from transformers import TimesformerConfig, VideoMAEImageProcessor\n",
    "\n",
    "\n",
    "def rename_key(name):\n",
    "    a = name\n",
    "    \n",
    "    if \"encoder.\" in name:\n",
    "        name = name.replace(\"encoder.\", \"\")\n",
    "    if \"cls_token\" in name:\n",
    "        name = name.replace(\"cls_token\", \"embeddings.cls_token\")\n",
    "    if \"pos_embed\" in name:\n",
    "        name = name.replace(\"pos_embed\", \"embeddings.position_embeddings\")\n",
    "    if \"time_embed\" in name:\n",
    "        name = name.replace(\"time_embed\", \"embeddings.time_embeddings\")\n",
    "    if \"patch_embed.proj\" in name:\n",
    "        name = name.replace(\"patch_embed.proj\", \"embeddings.patch_embeddings.projection\")\n",
    "    if \"patch_embed.norm\" in name:\n",
    "        name = name.replace(\"patch_embed.norm\", \"embeddings.norm\")\n",
    "    if \"blocks\" in name:\n",
    "        name = name.replace(\"blocks\", \"encoder.layer\")\n",
    "    if \"attn.proj\" in name:\n",
    "        name = name.replace(\"attn.proj\", \"attention.output.dense\")\n",
    "    if \"attn\" in name and \"bias\" not in name and \"temporal\" not in name:\n",
    "        name = name.replace(\"attn\", \"attention.self\")\n",
    "    if \"attn\" in name and \"temporal\" not in name:\n",
    "        name = name.replace(\"attn\", \"attention.attention\")\n",
    "    if \"temporal_norm1\" in name:\n",
    "        name = name.replace(\"temporal_norm1\", \"temporal_layernorm\")\n",
    "    if \"temporal_attn.proj\" in name:\n",
    "        name = name.replace(\"temporal_attn\", \"temporal_attention.output.dense\")\n",
    "    if \"temporal_fc\" in name:\n",
    "        name = name.replace(\"temporal_fc\", \"temporal_dense\")\n",
    "    if \"norm1\" in name and \"temporal\" not in name:\n",
    "        name = name.replace(\"norm1\", \"layernorm_before\")\n",
    "    if \"norm2\" in name:\n",
    "        name = name.replace(\"norm2\", \"layernorm_after\")\n",
    "    if \"mlp.fc1\" in name:\n",
    "        name = name.replace(\"mlp.fc1\", \"intermediate.dense\")\n",
    "    if \"mlp.fc2\" in name:\n",
    "        name = name.replace(\"mlp.fc2\", \"output.dense\")\n",
    "    if \"norm.weight\" in name and \"fc\" not in name and \"temporal\" not in name:\n",
    "        name = name.replace(\"norm.weight\", \"layernorm.weight\")\n",
    "    if \"norm.bias\" in name and \"fc\" not in name and \"temporal\" not in name:\n",
    "        name = name.replace(\"norm.bias\", \"layernorm.bias\")\n",
    "    if \"head\" in name:\n",
    "        name = name.replace(\"head\", \"classifier\")\n",
    "\n",
    "    if name == a:\n",
    "        i = 1\n",
    "    \n",
    "    return name\n",
    "\n",
    "\n",
    "def convert_state_dict(orig_state_dict, config):\n",
    "    for key in orig_state_dict.copy().keys():\n",
    "        val = orig_state_dict.pop(key)\n",
    "\n",
    "        if key.startswith(\"feature_extractor.model.\"):\n",
    "            key = key.replace(\"feature_extractor.model.\", \"\")\n",
    "\n",
    "        if \"qkv\" in key:\n",
    "            key_split = key.split(\".\")\n",
    "            layer_num = int(key_split[1])\n",
    "            prefix = \"encoder.layer.\"\n",
    "            if \"temporal\" in key:\n",
    "                postfix = \".temporal_attention.attention.qkv.\"\n",
    "            else:\n",
    "                postfix = \".attention.attention.qkv.\"\n",
    "            if \"weight\" in key:\n",
    "                orig_state_dict[f\"{prefix}{layer_num}{postfix}weight\"] = val\n",
    "            else:\n",
    "                orig_state_dict[f\"{prefix}{layer_num}{postfix}bias\"] = val\n",
    "        else:\n",
    "            orig_state_dict[rename_key(key)] = val\n",
    "\n",
    "    return orig_state_dict\n",
    "\n",
    "\n",
    "# We will verify our results on a video of eating spaghetti\n",
    "# Frame indices used: [164 168 172 176 181 185 189 193 198 202 206 210 215 219 223 227]\n",
    "def prepare_video():\n",
    "    file = hf_hub_download(\n",
    "        repo_id=\"hf-internal-testing/spaghetti-video\", filename=\"eating_spaghetti.npy\", repo_type=\"dataset\"\n",
    "    )\n",
    "    video = np.load(file)\n",
    "    return list(video)\n",
    "\n",
    "\n",
    "def convert_timesformer_checkpoint(config):\n",
    "    model = TimesformerModel(config)\n",
    "\n",
    "    # download original checkpoint, hosted on Google Drive\n",
    "    output = \"../weights/base.pth\"\n",
    "    state_dict = torch.load(output, map_location=\"cpu\")\n",
    "    new_state_dict = convert_state_dict(state_dict.copy(), config)\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # verify model on basic input\n",
    "    image_processor = VideoMAEImageProcessor(image_mean=[0.5, 0.5, 0.5], image_std=[0.5, 0.5, 0.5])\n",
    "    video = prepare_video()\n",
    "    inputs = image_processor(video[:8], return_tensors=\"pt\")\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Перевод модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Transformers используется некорректная инициализация модели, есть различия с оригинальным timesformer от meta. В файле modeling_timesformer.py строку \n",
    "```\n",
    "self.drop_path = TimeSformerDropPath(config.drop_path_rate) if drop_path_rate > 0.0 else nn.Identity()\n",
    "``` \n",
    "\n",
    "нужно заменить на \n",
    "```\n",
    "self.drop_path = TimeSformerDropPath(drop_path_rate) if drop_path_rate > 0.0 else nn.Identity()\n",
    "```\n",
    "из-за того, что drop_path_rate должен меняться с каждой головой. Тогда выходы будут совпадать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_195826/2619605470.py:100: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(output, map_location=\"cpu\")\n",
      "/home/borntowarn/projects/borntowarn/piracy_detection/venv/lib/python3.11/site-packages/transformers/feature_extraction_utils.py:141: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  return torch.tensor(value)\n"
     ]
    }
   ],
   "source": [
    "# base model\n",
    "tr_config = TimesformerConfig(image_size=224, patch_size=16, num_frames=8, drop_path_rate=0.1)\n",
    "model = convert_timesformer_checkpoint(tr_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small model\n",
    "tr_config = TimesformerConfig(\n",
    "    image_size=224,\n",
    "    patch_size=16,\n",
    "    num_frames=8,\n",
    "    drop_path_rate=0.1,\n",
    "    hidden_size=384,\n",
    "    intermediate_size=1536,\n",
    "    num_attention_heads=6\n",
    ")\n",
    "model = convert_timesformer_checkpoint(tr_config)\n",
    "# model = TimesformerModel.from_pretrained('../weights/csl_transformers_small/').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimesformerModel(\n",
       "  (embeddings): TimesformerEmbeddings(\n",
       "    (patch_embeddings): TimesformerPatchEmbeddings(\n",
       "      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (time_drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): TimesformerEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): TimesformerLayer(\n",
       "        (drop_path): Identity()\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (1): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.00909090880304575)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (2): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.0181818176060915)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (3): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.027272727340459824)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (4): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.036363635212183)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (5): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.045454543083906174)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (6): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.054545458406209946)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (7): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.06363636255264282)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (8): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.0727272778749466)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (9): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.08181818574666977)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (10): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.09090909361839294)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (11): TimesformerLayer(\n",
       "        (drop_path): TimeSformerDropPath(p=0.10000000149011612)\n",
       "        (attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): TimesformerIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): TimesformerOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (temporal_attention): TimeSformerAttention(\n",
       "          (attention): TimesformerSelfAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): TimesformerSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (temporal_dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((2, 3, 8, 224, 224)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inp.permute(0, 2, 1, 3, 4)).last_hidden_state[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "orig_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(torch.abs(orig_model(inp) - model(inp.permute(0, 2, 1, 3, 4)).last_hidden_state[:, 0]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохраняем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('../weights/csl_transformers_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimesformerModel.from_pretrained('../weights/csl_transformers_base/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder.layer.2.intermediate.dense',\n",
       " 'encoder.layer.4.intermediate.dense',\n",
       " 'encoder.layer.3.temporal_dense',\n",
       " 'encoder.layer.0.temporal_dense',\n",
       " 'encoder.layer.8.attention.attention.qkv',\n",
       " 'encoder.layer.9.attention.output.dense',\n",
       " 'encoder.layer.1.intermediate.dense',\n",
       " 'encoder.layer.0.output.dense',\n",
       " 'encoder.layer.8.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.9.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.0.attention.attention.qkv',\n",
       " 'encoder.layer.11.temporal_dense',\n",
       " 'encoder.layer.1.attention.attention.qkv',\n",
       " 'encoder.layer.4.temporal_attention.output.dense',\n",
       " 'encoder.layer.10.temporal_attention.output.dense',\n",
       " 'encoder.layer.10.attention.output.dense',\n",
       " 'encoder.layer.6.attention.attention.qkv',\n",
       " 'encoder.layer.8.temporal_dense',\n",
       " 'encoder.layer.3.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.0.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.11.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.2.temporal_attention.output.dense',\n",
       " 'encoder.layer.3.output.dense',\n",
       " 'encoder.layer.7.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.7.attention.attention.qkv',\n",
       " 'encoder.layer.7.intermediate.dense',\n",
       " 'encoder.layer.8.temporal_attention.output.dense',\n",
       " 'encoder.layer.6.output.dense',\n",
       " 'encoder.layer.2.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.10.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.5.output.dense',\n",
       " 'encoder.layer.3.attention.attention.qkv',\n",
       " 'encoder.layer.11.output.dense',\n",
       " 'encoder.layer.9.temporal_attention.output.dense',\n",
       " 'encoder.layer.7.attention.output.dense',\n",
       " 'encoder.layer.2.output.dense',\n",
       " 'encoder.layer.6.intermediate.dense',\n",
       " 'encoder.layer.10.attention.attention.qkv',\n",
       " 'encoder.layer.9.output.dense',\n",
       " 'encoder.layer.5.attention.attention.qkv',\n",
       " 'encoder.layer.11.temporal_attention.output.dense',\n",
       " 'encoder.layer.4.attention.output.dense',\n",
       " 'encoder.layer.6.temporal_dense',\n",
       " 'encoder.layer.9.intermediate.dense',\n",
       " 'encoder.layer.7.output.dense',\n",
       " 'encoder.layer.6.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.11.attention.attention.qkv',\n",
       " 'encoder.layer.1.output.dense',\n",
       " 'encoder.layer.9.temporal_dense',\n",
       " 'encoder.layer.8.output.dense',\n",
       " 'encoder.layer.0.intermediate.dense',\n",
       " 'encoder.layer.5.temporal_dense',\n",
       " 'encoder.layer.7.temporal_attention.output.dense',\n",
       " 'encoder.layer.4.attention.attention.qkv',\n",
       " 'encoder.layer.4.temporal_dense',\n",
       " 'encoder.layer.6.attention.output.dense',\n",
       " 'encoder.layer.7.temporal_dense',\n",
       " 'encoder.layer.5.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.1.temporal_attention.output.dense',\n",
       " 'embeddings.patch_embeddings.projection',\n",
       " 'encoder.layer.8.attention.output.dense',\n",
       " 'encoder.layer.1.temporal_dense',\n",
       " 'encoder.layer.0.attention.output.dense',\n",
       " 'encoder.layer.3.temporal_attention.output.dense',\n",
       " 'encoder.layer.2.temporal_dense',\n",
       " 'encoder.layer.1.attention.output.dense',\n",
       " 'encoder.layer.11.attention.output.dense',\n",
       " 'encoder.layer.10.intermediate.dense',\n",
       " 'encoder.layer.0.temporal_attention.output.dense',\n",
       " 'encoder.layer.6.temporal_attention.output.dense',\n",
       " 'encoder.layer.9.attention.attention.qkv',\n",
       " 'encoder.layer.3.intermediate.dense',\n",
       " 'encoder.layer.4.output.dense',\n",
       " 'encoder.layer.2.attention.output.dense',\n",
       " 'encoder.layer.10.temporal_dense',\n",
       " 'encoder.layer.8.intermediate.dense',\n",
       " 'encoder.layer.4.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.10.output.dense',\n",
       " 'encoder.layer.5.intermediate.dense',\n",
       " 'encoder.layer.5.attention.output.dense',\n",
       " 'encoder.layer.2.attention.attention.qkv',\n",
       " 'encoder.layer.11.intermediate.dense',\n",
       " 'encoder.layer.1.temporal_attention.attention.qkv',\n",
       " 'encoder.layer.3.attention.output.dense',\n",
       " 'encoder.layer.5.temporal_attention.output.dense']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Conv1D\n",
    "\n",
    "def get_specific_layer_names(model):\n",
    "    # Create a list to store the layer names\n",
    "    layer_names = []\n",
    "    \n",
    "    # Recursively visit all modules and submodules\n",
    "    for name, module in model.named_modules():\n",
    "        # Check if the module is an instance of the specified layers\n",
    "        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.Conv2d, Conv1D)):\n",
    "            # model name parsing \n",
    "\n",
    "            layer_names.append(name)\n",
    "    \n",
    "    return layer_names\n",
    "\n",
    "list(set(get_specific_layer_names(model)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
